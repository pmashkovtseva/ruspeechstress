в этой и паре следующих лекций мы рассмотрим разные задачи, которые в нашей предметной области есть. можно выделить три высокоуровневые группы задач обработки текстов на естественном языке. первая группа — это лингвистический анализ. методы из области лингвистического анализа направлены на разбор структуры текста на разных уровнях. задачи из этой группы мы рассмотрим прямо в этой лекции. вторая группа — методы извлечения признаков из текстов. они частично пересекаются с первой группой, но, в то время как задачи лингвистического анализа — это самостоятельные задачи, задачи извлечения признаков всегда предшествуют применению методов машинного обучения. третья группа — прикладные задачи, они ближе к бизнесу, к пользователю. как правило, для их решения используются методы из первых групп плюс какие-то специальные надстройки. рассмотрим задачи, входящие в лингвистический анализ текстов. цель: извлечение структуры текста. как мы уже говорили ранее, решаются задачи в порядке от низкоуровневых к более высокоуровневым. сначала мы разбиваем текст на предложение и токены. за это отвечает графематический анализ. потом разбираем каждое предложение от морфологии до семантики. затем разбираем связи предложений друг с другом, чтобы структурировать повествование, анализируем дискурс. отдельно стоит задача генерации текста — это не про анализ, это про синтез. как правило, для решения каждой задачи используются результаты всех предыдущих. итак, графематический анализ принимает на вход сырой текст и возвращает разбиение на токены и предложения. для его реализации, в простейшем случае, используются регулярные выражения. мы просто находим все разделительные символы — пробелы и знаки препинания, а потом из них отбираем только те, которые соответствуют окончанию предложения. часто не очень просто определить, какая точка обозначает окончание предложения, а какая — сокращение. например, в этом предложении есть фамилия, имя, отчество. имя и отчество сокращены, а дальше следует "точка". какая из этих трёх точек обозначает конец предложения? чтобы убрать эту неоднозначность на практике, после регулярных выражений, используются вероятностные модели, описывающие совместное распределение вероятностей меток токенов. к таким моделям относятся случайные условные поля или скрытые марковские модели. мы не будем подробно их рассматривать в данном курсе, но важно, чтобы вы знали, что такие модели есть и знали, как они называются, чтобы могли самостоятельно почитать. морфологический анализ работает с отдельными токенами. для каждого токена анализатор предлагает набор сочетаний характеристик, к которым относится часть речи, падеж, число, начальная форма... при этом анализатор не может выбрать только одно сочетание характеристик, потому что для этого нужно привлекать более широкий контекст. другими словами, частеречная омонимия пока не разрешается. например, для слова "мыла" вот в такой форме анализатор предложит два варианта: это прошедшее время и женский род глагола "мыть", а также родительный падеж и единственное число "мыло". для реализации используются разные методы, самый простой из которых — словарный. для частотных словоформ все возможные варианты уже известны наперёд, надо их только достать. а для неизвестных или редких слов используются регулярные выражения, системы правил, которые по окончанию слова пытаются предположить, как должна выглядеть начальная форма этого слова, а также морфологические характеристики этой словоформы. логичный следующий шаг — это для каждого токена, из всех вариантов, предложенных для него морфологическим анализатором, выбрать только один, то есть разрешить частеречную омонимию. омонимия снимается в рамках одного предложения. такого контекста на практике достаточно почти всегда. в результате из всего множества вариантов выбирается только один — например, "глагол". для решения этой задачи существуют методы, основанные на правилах, в том числе полученных с помощью машинного обучения. однако более современный и более распространённый вариант — это вероятностные модели и последовательности, то есть условные случайные поля и марковские модели. когда размеченный корпус достаточно большой, рекуррентные нейросети позволяют улучшить качество ещё сильнее.